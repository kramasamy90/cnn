{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 14:45:30.814207: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734772530.831164   34859 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734772530.836170   34859 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-21 14:45:30.854384: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/kramasamy/.venv/globalenv/lib/python3.10/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.23 (you have 1.4.22). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "import mlflow\n",
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../configs')\n",
    "sys.path.append('../../../utils')\n",
    "from search_space_pretrained_unet import search_space\n",
    "from unet import Unet\n",
    "from train_utils import Trainer, he_init, OptimizerFactory\n",
    "from eval_utils import get_pixel_accuracy, evaluate_model\n",
    "from tune_utils import get_config\n",
    "from isbi_em_dataset import ISBIEMDataset\n",
    "from utils import flatten_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants.\n",
    "split_ratio = 0.8 # train / valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.25)\n",
    "])\n",
    "DATA_DIR = '/home/kramasamy/Code/projects/cnn/data/isbi_em_segmentation'\n",
    "train_dataset = ISBIEMDataset(DATA_DIR, transform=transform, train=False)\n",
    "\n",
    "total_size = len(train_dataset)\n",
    "train_size = int(total_size * split_ratio)\n",
    "valid_size = total_size - train_size\n",
    "\n",
    "train_dataset, valid_dataset = random_split(train_dataset, \n",
    "                                            [train_size, valid_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import yaml \n",
    "\n",
    "pretrain_unet_result = pkl.load(open('../checkpoints/pretrain_unet_results.pkl', 'rb'))\n",
    "pretrained_unet = pretrain_unet_result['model'].unet\n",
    "\n",
    "with open('../configs/train_pretrained_config.yaml', 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(params, log_to_mlflow=True):\n",
    "    torch.cuda.empty_cache()\n",
    "    config = deepcopy(get_config(params))\n",
    "    torch.cuda.empty_cache()\n",
    "    model = Unet()\n",
    "    model.apply(he_init)\n",
    "    model.load_state_dict(pretrained_unet.state_dict())\n",
    "\n",
    "    # Custom optimizer.\n",
    "    encoder_params = list(model.block1.parameters()) + \\\n",
    "                    list(model.block2.parameters()) + \\\n",
    "                    list(model.block3.parameters()) + \\\n",
    "                    list(model.block4.parameters()) + \\\n",
    "                    list(model.block5.parameters())\n",
    "\n",
    "    decoder_params = list(model.block6.parameters()) + \\\n",
    "                    list(model.block7.parameters()) + \\\n",
    "                    list(model.block8.parameters()) + \\\n",
    "                    list(model.block9.parameters()) + \\\n",
    "                    list(model.final_conv.parameters())\n",
    "\n",
    "    optimizer_factory = OptimizerFactory(config['optimizer'])\n",
    "    lr = config['optimizer']['params']['lr']\n",
    "    del config['optimizer']['params']['lr']\n",
    "    optimizer = optimizer_factory.get_optimizer([\n",
    "        {'params': encoder_params, 'lr': lr / config['optimizer']['lr_damp_pretrained']},  \n",
    "        {'params': decoder_params, 'lr': lr}   # Larger LR for decoder\n",
    "    ])\n",
    "\n",
    "    trainer = Trainer(model, train_dataset, config)\n",
    "    result = trainer.train(optimizer=optimizer, progress_bar=False)\n",
    "    valid_loader = DataLoader(dataset=train_dataset, batch_size=2, \n",
    "                              shuffle=False)\n",
    "    torch.cuda.empty_cache()\n",
    "    y_pred, y_true = evaluate_model(result['model'], valid_loader, 'cuda')\n",
    "    accuracy = get_pixel_accuracy(y_pred, y_true)\n",
    "\n",
    "    if log_to_mlflow:\n",
    "        with mlflow.start_run(nested=True):\n",
    "            mlflow.log_params(flatten_params(params))\n",
    "            mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    return -1 * accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [4:32:18<00:00, 163.39s/trial, best loss: -84.77850341796875] \n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"tune_pretrained_unet\"\n",
    "mlflow.set_tracking_uri(\"/home/kramasamy/Code/projects/cnn/models/unet/logs/mlflow\")\n",
    "mlflow.set_experiment(experiment_name=experiment_name)\n",
    "with mlflow.start_run():\n",
    "    trials = Trials()\n",
    "    best_params = fmin(\n",
    "        fn = objective_function,\n",
    "        space = search_space,\n",
    "        algo = tpe.suggest,\n",
    "        max_evals = 100,\n",
    "        trials = trials\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "globalenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
